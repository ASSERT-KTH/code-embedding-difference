{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44215f6-5760-4718-8f47-aa7df5f0caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7ffa98-3a2a-48e8-8947-ed12b223a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 11:04:24.292631: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-16 11:04:24.372332: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-16 11:04:24.372371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-16 11:04:24.375900: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "model_id = \"answerdotai/ModernBERT-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"NicholasOgenstad/my-runbugrun-dataset\",\n",
    "    data_files=\"runbugrun_all_pairs_with_language.json\",\n",
    "    split=\"train\"\n",
    ")\n",
    "dataset = dataset.filter(lambda example: example[\"language\"] != \"tests\")\n",
    "\n",
    "buggy = dataset['buggy_code']\n",
    "fixed = dataset['fixed_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48193c5a-6c0d-4e5d-8e76-4cbe65528283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenized_chunk(save_dir, chunk_num):\n",
    "    chunk_file = os.path.join(save_dir, f'chunk_{chunk_num:04d}.pkl')\n",
    "    with open(chunk_file, 'rb') as f:\n",
    "        chunk_data = pickle.load(f)\n",
    "\n",
    "    current_chunk_size = chunk_data['chunk_size']\n",
    "    \n",
    "    buggy_tokenized = {\n",
    "       'input_ids': chunk_data['input_ids'][:current_chunk_size],\n",
    "       'attention_mask': chunk_data['attention_mask'][:current_chunk_size]\n",
    "    }\n",
    "    \n",
    "    fixed_tokenized = {\n",
    "       'input_ids': chunk_data['input_ids'][current_chunk_size:],\n",
    "       'attention_mask': chunk_data['attention_mask'][current_chunk_size:]\n",
    "    }\n",
    "\n",
    "    return buggy_tokenized, fixed_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e77973-db00-4f0b-b6e6-1fd6b8d6fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_pooled_embeddings(input_ids, attention_mask):\n",
    "    with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden = outputs.last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).expand_as(hidden).float()\n",
    "        summed = (hidden * mask).sum(1)\n",
    "        counts = mask.sum(1).clamp(min=1e-9)\n",
    "        return summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9140b2d-dd25-485c-af13-1589bb84d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_diff_file(chunk_num, diff_array):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    diff_embeddings = torch.cat(diff_array, dim=0)\n",
    "    diff_embeddings_np = diff_embeddings.cpu().numpy()\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f'diff_embeddings_chunk_{chunk_num:04d}.pkl')\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(diff_embeddings_np, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89acb64d-a046-467b-95a0-f1bfe45965d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_in_batches(encodings, batch_size=192):\n",
    "    total = encodings['input_ids'].shape[0]\n",
    "    encodings = {k: v.to(model.device, non_blocking=True) for k, v in encodings.items()}\n",
    "    pooled_outputs = []\n",
    "\n",
    "    for  start_idx in range(0, total, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total)\n",
    "\n",
    "        input_ids_batch = encodings[\"input_ids\"][start_idx:end_idx]\n",
    "        attention_mask_batch = encodings[\"attention_mask\"][start_idx:end_idx]\n",
    "        pooled = get_mean_pooled_embeddings(input_ids_batch, attention_mask_batch)\n",
    "        pooled_outputs.append(pooled)\n",
    "\n",
    "    all_embeddings = torch.cat(pooled_outputs)\n",
    "\n",
    "    return all_embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a0ff9-1007-4f2b-9709-d16a3f2f93dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 16, batch 0\n",
      "Processing chunk 16, batch 1\n",
      "Processing chunk 16, batch 2\n",
      "Processing chunk 16, batch 3\n",
      "Processing chunk 16, batch 4\n",
      "Processing chunk 16, batch 5\n",
      "Processing chunk 16, batch 6\n",
      "Processing chunk 16, batch 7\n",
      "Processing chunk 16, batch 8\n",
      "Processing chunk 16, batch 9\n",
      "Processing chunk 16, batch 10\n",
      "Processing chunk 16, batch 11\n",
      "Processing chunk 16, batch 12\n",
      "Processing chunk 16, batch 13\n",
      "Processing chunk 16, batch 14\n",
      "Processing chunk 16, batch 15\n",
      "Processing chunk 16, batch 16\n",
      "Processing chunk 16, batch 17\n",
      "Processing chunk 16, batch 18\n",
      "Processing chunk 16, batch 19\n",
      "Saved diff embeddings for chunk 16 to /mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2/diff_embeddings_chunk_0016.pkl\n",
      "Shape: (20000, 1024)\n",
      "Processing chunk 17, batch 0\n",
      "Processing chunk 17, batch 1\n",
      "Processing chunk 17, batch 2\n",
      "Processing chunk 17, batch 3\n",
      "Processing chunk 17, batch 4\n",
      "Processing chunk 17, batch 5\n",
      "Processing chunk 17, batch 6\n",
      "Processing chunk 17, batch 7\n",
      "Processing chunk 17, batch 8\n",
      "Processing chunk 17, batch 9\n",
      "Processing chunk 17, batch 10\n",
      "Processing chunk 17, batch 11\n",
      "Processing chunk 17, batch 12\n",
      "Processing chunk 17, batch 13\n",
      "Processing chunk 17, batch 14\n",
      "Processing chunk 17, batch 15\n",
      "Processing chunk 17, batch 16\n",
      "Processing chunk 17, batch 17\n",
      "Processing chunk 17, batch 18\n",
      "Processing chunk 17, batch 19\n",
      "Saved diff embeddings for chunk 17 to /mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2/diff_embeddings_chunk_0017.pkl\n",
      "Shape: (20000, 1024)\n",
      "Processing chunk 18, batch 0\n",
      "Processing chunk 18, batch 1\n",
      "Processing chunk 18, batch 2\n",
      "Processing chunk 18, batch 3\n",
      "Processing chunk 18, batch 4\n",
      "Processing chunk 18, batch 5\n",
      "Processing chunk 18, batch 6\n",
      "Processing chunk 18, batch 7\n",
      "Processing chunk 18, batch 8\n",
      "Processing chunk 18, batch 9\n",
      "Processing chunk 18, batch 10\n",
      "Processing chunk 18, batch 11\n",
      "Processing chunk 18, batch 12\n",
      "Processing chunk 18, batch 13\n",
      "Processing chunk 18, batch 14\n",
      "Processing chunk 18, batch 15\n",
      "Processing chunk 18, batch 16\n",
      "Processing chunk 18, batch 17\n",
      "Processing chunk 18, batch 18\n",
      "Processing chunk 18, batch 19\n",
      "Saved diff embeddings for chunk 18 to /mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2/diff_embeddings_chunk_0018.pkl\n",
      "Shape: (20000, 1024)\n",
      "Processing chunk 19, batch 0\n",
      "Processing chunk 19, batch 1\n",
      "Processing chunk 19, batch 2\n",
      "Processing chunk 19, batch 3\n",
      "Processing chunk 19, batch 4\n",
      "Processing chunk 19, batch 5\n",
      "Processing chunk 19, batch 6\n",
      "Processing chunk 19, batch 7\n",
      "Processing chunk 19, batch 8\n",
      "Processing chunk 19, batch 9\n",
      "Processing chunk 19, batch 10\n",
      "Processing chunk 19, batch 11\n",
      "Processing chunk 19, batch 12\n",
      "Processing chunk 19, batch 13\n",
      "Processing chunk 19, batch 14\n",
      "Processing chunk 19, batch 15\n",
      "Processing chunk 19, batch 16\n",
      "Processing chunk 19, batch 17\n",
      "Processing chunk 19, batch 18\n",
      "Processing chunk 19, batch 19\n",
      "Saved diff embeddings for chunk 19 to /mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2/diff_embeddings_chunk_0019.pkl\n",
      "Shape: (20000, 1024)\n",
      "Processing chunk 20, batch 0\n",
      "Processing chunk 20, batch 1\n",
      "Processing chunk 20, batch 2\n",
      "Processing chunk 20, batch 3\n",
      "Processing chunk 20, batch 4\n",
      "Processing chunk 20, batch 5\n",
      "Processing chunk 20, batch 6\n",
      "Processing chunk 20, batch 7\n",
      "Processing chunk 20, batch 8\n",
      "Processing chunk 20, batch 9\n",
      "Processing chunk 20, batch 10\n",
      "Processing chunk 20, batch 11\n",
      "Processing chunk 20, batch 12\n",
      "Processing chunk 20, batch 13\n",
      "Processing chunk 20, batch 14\n",
      "Processing chunk 20, batch 15\n",
      "Processing chunk 20, batch 16\n",
      "Processing chunk 20, batch 17\n",
      "Processing chunk 20, batch 18\n",
      "Processing chunk 20, batch 19\n",
      "Saved diff embeddings for chunk 20 to /mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2/diff_embeddings_chunk_0020.pkl\n",
      "Shape: (20000, 1024)\n",
      "Processing chunk 21, batch 0\n",
      "Processing chunk 21, batch 1\n",
      "Processing chunk 21, batch 2\n",
      "Processing chunk 21, batch 3\n",
      "Processing chunk 21, batch 4\n",
      "Processing chunk 21, batch 5\n",
      "Processing chunk 21, batch 6\n",
      "Processing chunk 21, batch 7\n",
      "Processing chunk 21, batch 8\n",
      "Processing chunk 21, batch 9\n",
      "Processing chunk 21, batch 10\n",
      "Processing chunk 21, batch 11\n",
      "Processing chunk 21, batch 12\n",
      "Processing chunk 21, batch 13\n",
      "Processing chunk 21, batch 14\n",
      "Processing chunk 21, batch 15\n",
      "Processing chunk 21, batch 16\n",
      "Processing chunk 21, batch 17\n",
      "Processing chunk 21, batch 18\n",
      "Processing chunk 21, batch 19\n",
      "Saved diff embeddings for chunk 21 to /mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2/diff_embeddings_chunk_0021.pkl\n",
      "Shape: (20000, 1024)\n",
      "Processing chunk 22, batch 0\n",
      "Processing chunk 22, batch 1\n",
      "Processing chunk 22, batch 2\n",
      "Processing chunk 22, batch 3\n",
      "Processing chunk 22, batch 4\n",
      "Processing chunk 22, batch 5\n",
      "Processing chunk 22, batch 6\n",
      "Processing chunk 22, batch 7\n",
      "Processing chunk 22, batch 8\n",
      "Processing chunk 22, batch 9\n",
      "Processing chunk 22, batch 10\n",
      "Processing chunk 22, batch 11\n",
      "Processing chunk 22, batch 12\n"
     ]
    }
   ],
   "source": [
    "tokenized_dir = \"/mimer/NOBACKUP/groups/naiss2025-5-243/tokenized_chunks2\"\n",
    "output_dir = \"/mimer/NOBACKUP/groups/naiss2025-5-243/diff_embeddings2\"\n",
    "\n",
    "step_size = 1000\n",
    "\n",
    "for chunk_num in range(0, 23):\n",
    "    \n",
    "    buggy_data, fixed_data = load_tokenized_chunk(tokenized_dir, chunk_num)\n",
    "    total_size = buggy_data['input_ids'].shape[0]\n",
    "    \n",
    "    diff_final = []\n",
    "    for batch_idx in range(20):\n",
    "        print(f\"Processing chunk {chunk_num}, batch {batch_idx}\")\n",
    "        start = batch_idx * step_size\n",
    "        end = min(start + step_size, total_size)\n",
    "        \n",
    "        buggy_batch = {\n",
    "            'input_ids': buggy_data['input_ids'][start:end],\n",
    "            'attention_mask': buggy_data['attention_mask'][start:end]\n",
    "        }\n",
    "        fixed_batch = {\n",
    "            'input_ids': fixed_data['input_ids'][start:end],\n",
    "            'attention_mask': fixed_data['attention_mask'][start:end]\n",
    "        }\n",
    "    \n",
    "        buggy = embed_in_batches(buggy_batch)\n",
    "        fixed = embed_in_batches(fixed_batch)\n",
    "    \n",
    "        diff_batch = fixed - buggy\n",
    "        diff_final.append(diff_batch)\n",
    "\n",
    "    write_diff_file(chunk_num, diff_final)\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testenv3",
   "language": "python",
   "name": "testenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
