{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2e862a-0c33-4b04-ba7b-5c3e7a54bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "buggy_list = []\n",
    "fixed_list = []\n",
    "\n",
    "base_dir = \"/mimer/NOBACKUP/groups/naiss2025-5-243/buggy_fixed_embeddings\" # Location of buggy+fixed pairs\n",
    "\n",
    "for chunk_num in range(23):\n",
    "    file_path = f\"{base_dir}/buggy_fixed_embeddings_chunk_{chunk_num:04d}.pkl\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        buggy_list.extend(data['buggy_embeddings'].tolist())\n",
    "        fixed_list.extend(data['fixed_embeddings'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b403d6e2-217c-4d51-8bef-4cc346a36313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pairs = list(zip(buggy_list, fixed_list))\n",
    "random.shuffle(pairs)\n",
    "\n",
    "train_size = int(0.8 * len(pairs))\n",
    "val_size = int(0.1 * len(pairs))\n",
    "\n",
    "train_pairs = pairs[:train_size]\n",
    "val_pairs = pairs[train_size:train_size+val_size]\n",
    "test_pairs = pairs[train_size+val_size:]\n",
    "\n",
    "train_buggy, train_fixed = zip(*train_pairs)\n",
    "val_buggy, val_fixed = zip(*val_pairs)\n",
    "test_buggy, test_fixed = zip(*test_pairs)\n",
    "\n",
    "train_buggy = np.array(train_buggy)\n",
    "train_fixed = np.array(train_fixed)\n",
    "val_buggy = np.array(val_buggy)\n",
    "val_fixed = np.array(val_fixed)\n",
    "test_buggy = np.array(test_buggy)\n",
    "test_fixed = np.array(test_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27908103-77c8-4f93-91b4-3ddefcc092ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: train_loss=0.015660, val_loss=0.008174, train_sim=0.983648, val_sim=0.991775\n",
      "2: train_loss=0.006955, val_loss=0.005954, train_sim=0.993013, val_sim=0.993935\n",
      "3: train_loss=0.005502, val_loss=0.005095, train_sim=0.994503, val_sim=0.994987\n",
      "4: train_loss=0.004734, val_loss=0.004361, train_sim=0.995276, val_sim=0.995566\n",
      "5: train_loss=0.004270, val_loss=0.004503, train_sim=0.995750, val_sim=0.995486\n",
      "6: train_loss=0.003923, val_loss=0.003966, train_sim=0.996084, val_sim=0.996099\n",
      "7: train_loss=0.003649, val_loss=0.003462, train_sim=0.996361, val_sim=0.996490\n",
      "8: train_loss=0.003455, val_loss=0.003353, train_sim=0.996551, val_sim=0.996648\n",
      "9: train_loss=0.003290, val_loss=0.003104, train_sim=0.996712, val_sim=0.996850\n",
      "10: train_loss=0.003251, val_loss=0.003107, train_sim=0.996776, val_sim=0.996853\n",
      "11: train_loss=0.003044, val_loss=0.002983, train_sim=0.996949, val_sim=0.996974\n",
      "12: train_loss=0.002966, val_loss=0.003161, train_sim=0.997034, val_sim=0.996811\n",
      "13: train_loss=0.002920, val_loss=0.002799, train_sim=0.997086, val_sim=0.997159\n",
      "14: train_loss=0.002792, val_loss=0.002767, train_sim=0.997196, val_sim=0.997213\n",
      "15: train_loss=0.002760, val_loss=0.003391, train_sim=0.997239, val_sim=0.996893\n",
      "16: train_loss=0.002690, val_loss=0.002866, train_sim=0.997299, val_sim=0.997220\n",
      "17: train_loss=0.002852, val_loss=0.002560, train_sim=0.997190, val_sim=0.997405\n",
      "18: train_loss=0.002573, val_loss=0.002575, train_sim=0.997401, val_sim=0.997413\n",
      "19: train_loss=0.002570, val_loss=0.002579, train_sim=0.997417, val_sim=0.997413\n",
      "20: train_loss=0.002534, val_loss=0.002705, train_sim=0.997450, val_sim=0.997376\n",
      "Test: loss=0.002678, sim=0.997401\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset\n",
    "class VectorPairDataset(Dataset):\n",
    "    def __init__(self, buggy, fixed):\n",
    "        self.buggy = torch.tensor(buggy, dtype=torch.float32)\n",
    "        self.fixed = torch.tensor(fixed, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.buggy)\n",
    "    def __getitem__(self, i):\n",
    "        return self.buggy[i], self.fixed[i]\n",
    "\n",
    "# Model\n",
    "class MLP_Model(nn.Module):\n",
    "    def __init__(self, input_size=1024, output_size=1024, hidden_sizes=[4096, 2048, 1024]):\n",
    "        super().__init__()\n",
    "        layers, in_f = [], input_size\n",
    "        for h in hidden_sizes:\n",
    "            layers += [nn.Linear(in_f, h), nn.ReLU()]\n",
    "            in_f = h\n",
    "        layers.append(nn.Linear(in_f, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Cosine similarity loss + MSE\n",
    "class MSECosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.cos = nn.CosineSimilarity(dim=1)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mse_loss = self.mse(x, y)\n",
    "        cosine_loss = 1 - self.cos(x, y).mean()\n",
    "        return self.alpha * mse_loss + self.beta * cosine_loss\n",
    "        \n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(VectorPairDataset(train_buggy, train_fixed), batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(VectorPairDataset(val_buggy, val_fixed), batch_size=512)\n",
    "test_loader = DataLoader(VectorPairDataset(test_buggy, test_fixed), batch_size=512)\n",
    "\n",
    "# Model\n",
    "model = MLP_Model(input_size=train_buggy.shape[1], output_size=train_fixed.shape[1]).to(device)\n",
    "\n",
    "# Loss + Optimizer\n",
    "loss_fn = MSECosineLoss(alpha=0.5, beta=0.5)\n",
    "cos_fn = nn.CosineSimilarity(dim=1)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    tloss, tsim = 0, 0\n",
    "    for b, f in train_loader:\n",
    "        b, f = b.to(device), f.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(b)\n",
    "        loss = loss_fn(out, f)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tloss += loss.item() * b.size(0)\n",
    "        tsim += cos_fn(out, f).mean().item() * b.size(0)\n",
    "    tloss /= len(train_loader.dataset)\n",
    "    tsim /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    vloss, vsim = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for b, f in val_loader:\n",
    "            b, f = b.to(device), f.to(device)\n",
    "            out = model(b)\n",
    "            vloss += loss_fn(out, f).item() * b.size(0)\n",
    "            vsim += cos_fn(out, f).mean().item() * b.size(0)\n",
    "    vloss /= len(val_loader.dataset)\n",
    "    vsim /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"{epoch+1}: train_loss={tloss:.6f}, val_loss={vloss:.6f}, \"\n",
    "          f\"train_sim={tsim:.6f}, val_sim={vsim:.6f}\")\n",
    "\n",
    "# Final test\n",
    "model.eval()\n",
    "test_loss, test_sim = 0, 0\n",
    "with torch.no_grad():\n",
    "    for b, f in test_loader:\n",
    "        b, f = b.to(device), f.to(device)\n",
    "        out = model(b)\n",
    "        test_loss += loss_fn(out, f).item() * b.size(0)\n",
    "        test_sim += cos_fn(out, f).mean().item() * b.size(0)\n",
    "print(f\"Test: loss={test_loss/len(test_loader.dataset):.6f}, \"\n",
    "      f\"sim={test_sim/len(test_loader.dataset):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1145f6-d262-4734-a7d5-1c83f8bc2bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testenv3",
   "language": "python",
   "name": "testenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
